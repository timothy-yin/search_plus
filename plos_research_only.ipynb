{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65764a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import FileLink\n",
    "\n",
    "def parse_authors_from_xml(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        soup = BeautifulSoup(f.read(), \"lxml-xml\")\n",
    "\n",
    "    doi_tag = soup.find(\"article-id\", {\"pub-id-type\": \"doi\"})\n",
    "    doi = doi_tag.text.strip() if doi_tag else \"N/A\"\n",
    "\n",
    "    title_tag = soup.find(\"article-title\")\n",
    "    title = title_tag.get_text(strip=True) if title_tag else \"N/A\"\n",
    "\n",
    "    abstract_tag = soup.find(\"abstract\")\n",
    "    abstract = abstract_tag.get_text(strip=True) if abstract_tag else \"N/A\"\n",
    "\n",
    "    keywords = soup.find_all(\"kwd\")\n",
    "    keywords_text = \"; \".join([kwd.text for kwd in keywords]) if keywords else \"N/A\"\n",
    "\n",
    "    subjects = soup.find_all(\"subject\")\n",
    "    subjects_text = \"; \".join([s.text for s in subjects]) if subjects else \"N/A\"\n",
    "\n",
    "    aff_dict = {}\n",
    "    for aff in soup.find_all(\"aff\"):\n",
    "        aff_id = aff.get(\"id\")\n",
    "\n",
    "        parts = []\n",
    "        institution = aff.find(\"institution\")\n",
    "        if institution:\n",
    "            parts.append(institution.get_text(strip=True))\n",
    "\n",
    "        addr = aff.find(\"addr-line\")\n",
    "        if addr:\n",
    "            parts.append(addr.get_text(strip=True))\n",
    "\n",
    "        country = aff.find(\"country\")\n",
    "        if country:\n",
    "            parts.append(country.get_text(strip=True))\n",
    "\n",
    "        if not parts:\n",
    "            label = aff.find(\"label\")\n",
    "            if label:\n",
    "                label.extract()\n",
    "            parts.append(aff.get_text(strip=True))\n",
    "\n",
    "        aff_text = \", \".join(parts)\n",
    "        aff_text = re.sub(r\"^\\d+\\s*\", \"\", aff_text)  # remove leading digits\n",
    "        aff_dict[aff_id] = aff_text\n",
    "\n",
    "        # 原本這一段要替換\n",
    "    author_group = soup.find(\"contrib-group\")\n",
    "    authors = author_group.find_all(\"contrib\", {\"contrib-type\": \"author\"}) if author_group else []\n",
    "\n",
    "    # ✅ 更嚴謹的有效作者篩選（避免 N/A 被當成作者）\n",
    "    valid_authors = []\n",
    "    for author in authors:\n",
    "        if author.find(\"surname\") or author.find(\"given-names\"):\n",
    "            valid_authors.append(author)\n",
    "\n",
    "    if not valid_authors:\n",
    "        return []\n",
    "\n",
    "    # ⬇️ 接下來請使用 valid_authors 而非原本的 authors\n",
    "    records = []\n",
    "    seen = set()\n",
    "    for idx, author in enumerate(valid_authors, 1):\n",
    "        surname = author.find(\"surname\")\n",
    "        given = author.find(\"given-names\")\n",
    "        name = f\"{given.text.strip()} {surname.text.strip()}\" if given and surname else surname.text.strip() if surname else \"N/A\"\n",
    "\n",
    "        if name in seen:\n",
    "            continue\n",
    "        seen.add(name)\n",
    "\n",
    "        role = []\n",
    "        if idx == 1:\n",
    "            role.append(\"第一作者\")\n",
    "        if author.find(\"xref\", {\"ref-type\": \"corresp\"}):\n",
    "            role.append(\"通訊作者\")\n",
    "\n",
    "        aff_ref = author.find(\"xref\", {\"ref-type\": \"aff\"})\n",
    "        aff_id = aff_ref.get(\"rid\") if aff_ref else None\n",
    "        aff_text = aff_dict.get(aff_id, \"N/A\")\n",
    "\n",
    "        records.append({\n",
    "            \"DOI\": doi,\n",
    "            \"Title\": title,\n",
    "            \"Author\": name,\n",
    "            \"Affiliation\": aff_text,\n",
    "            \"Role\": \", \".join(role) if role else \"作者\",\n",
    "            \"Abstract\": abstract,\n",
    "            \"Keywords\": keywords_text,\n",
    "            \"Subjects\": subjects_text,\n",
    "            \"FullText\": f\"{title} {abstract} {keywords_text} {subjects_text}\"\n",
    "        })\n",
    "\n",
    "\n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d0df960",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 50002/362279 [6:31:14<404:40:25,  4.67s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ 儲存進度：已處理 50000 筆\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 50100/362279 [6:31:24<9:06:59,  9.51it/s]  Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x10eb19400>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/timothy/Library/Python/3.13/lib/python/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n",
      " 14%|█▍        | 50283/362279 [6:31:43<40:30:35,  2.14it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, file \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(xml_files), \u001b[32m1\u001b[39m):\n\u001b[32m     12\u001b[39m     file_path = os.path.join(folder_path, file)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     records.extend(\u001b[43mparse_authors_from_xml\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m idx % batch_size == \u001b[32m0\u001b[39m:\n\u001b[32m     16\u001b[39m         df = pd.DataFrame(records)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mparse_authors_from_xml\u001b[39m\u001b[34m(file_path)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse_authors_from_xml\u001b[39m(file_path):\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m         soup = \u001b[43mBeautifulSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlxml-xml\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     doi_tag = soup.find(\u001b[33m\"\u001b[39m\u001b[33marticle-id\u001b[39m\u001b[33m\"\u001b[39m, {\u001b[33m\"\u001b[39m\u001b[33mpub-id-type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mdoi\u001b[39m\u001b[33m\"\u001b[39m})\n\u001b[32m     12\u001b[39m     doi = doi_tag.text.strip() \u001b[38;5;28;01mif\u001b[39;00m doi_tag \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mN/A\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/bs4/__init__.py:473\u001b[39m, in \u001b[36mBeautifulSoup.__init__\u001b[39m\u001b[34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[39m\n\u001b[32m    471\u001b[39m \u001b[38;5;28mself\u001b[39m.builder.initialize_soup(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_feed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m     success = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    475\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/bs4/__init__.py:658\u001b[39m, in \u001b[36mBeautifulSoup._feed\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    655\u001b[39m \u001b[38;5;28mself\u001b[39m.builder.reset()\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.markup \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m658\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmarkup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[38;5;66;03m# Close out any unfinished strings and close all the open tags.\u001b[39;00m\n\u001b[32m    660\u001b[39m \u001b[38;5;28mself\u001b[39m.endData()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/bs4/builder/_lxml.py:304\u001b[39m, in \u001b[36mLXMLTreeBuilderForXML.feed\u001b[39m\u001b[34m(self, markup)\u001b[39m\n\u001b[32m    302\u001b[39m         data = io.read(\u001b[38;5;28mself\u001b[39m.CHUNK_SIZE)\n\u001b[32m    303\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) != \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    305\u001b[39m     \u001b[38;5;28mself\u001b[39m.parser.close()\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m, \u001b[38;5;167;01mLookupError\u001b[39;00m, etree.ParserError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/lxml/parser.pxi:1331\u001b[39m, in \u001b[36mlxml.etree._FeedParser.feed\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/lxml/parser.pxi:1451\u001b[39m, in \u001b[36mlxml.etree._FeedParser.feed\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/lxml/parsertarget.pxi:161\u001b[39m, in \u001b[36mlxml.etree._TargetParserContext._handleParseResult\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/lxml/parsertarget.pxi:156\u001b[39m, in \u001b[36mlxml.etree._TargetParserContext._handleParseResult\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/lxml/etree.pyx:351\u001b[39m, in \u001b[36mlxml.etree._ExceptionContext._raise_if_stored\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/lxml/saxparser.pxi:391\u001b[39m, in \u001b[36mlxml.etree._handleSaxTargetStart\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/lxml/saxparser.pxi:466\u001b[39m, in \u001b[36mlxml.etree._callTargetSaxStart\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/lxml/parsertarget.pxi:94\u001b[39m, in \u001b[36mlxml.etree._PythonSaxParserTarget._handleSaxStart\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/bs4/builder/_lxml.py:393\u001b[39m, in \u001b[36mLXMLTreeBuilderForXML.start\u001b[39m\u001b[34m(self, tag, attrs, nsmap)\u001b[39m\n\u001b[32m    391\u001b[39m namespace, tag = \u001b[38;5;28mself\u001b[39m._getNsTag(tag)\n\u001b[32m    392\u001b[39m nsprefix = \u001b[38;5;28mself\u001b[39m._prefix_for_namespace(namespace)\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msoup\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_starttag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnsprefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfinal_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnamespaces\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mactive_namespace_prefixes\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/bs4/__init__.py:1019\u001b[39m, in \u001b[36mBeautifulSoup.handle_starttag\u001b[39m\u001b[34m(self, name, namespace, nsprefix, attrs, sourceline, sourcepos, namespaces)\u001b[39m\n\u001b[32m    997\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Called by the tree builder when a new tag is encountered.\u001b[39;00m\n\u001b[32m    998\u001b[39m \n\u001b[32m    999\u001b[39m \u001b[33;03m:param name: Name of the tag.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1016\u001b[39m \u001b[33;03m:meta private:\u001b[39;00m\n\u001b[32m   1017\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1018\u001b[39m \u001b[38;5;66;03m# print(\"Start tag %s: %s\" % (name, attrs))\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1019\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mendData\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28mself\u001b[39m.parse_only\n\u001b[32m   1023\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.tagStack) <= \u001b[32m1\u001b[39m\n\u001b[32m   1024\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.parse_only.allow_tag_creation(nsprefix, name, attrs)\n\u001b[32m   1025\u001b[39m ):\n\u001b[32m   1026\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/bs4/__init__.py:865\u001b[39m, in \u001b[36mBeautifulSoup.endData\u001b[39m\u001b[34m(self, containerClass)\u001b[39m\n\u001b[32m    863\u001b[39m containerClass = \u001b[38;5;28mself\u001b[39m.string_container(containerClass)\n\u001b[32m    864\u001b[39m o = containerClass(current_data)\n\u001b[32m--> \u001b[39m\u001b[32m865\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobject_was_parsed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/bs4/__init__.py:867\u001b[39m, in \u001b[36mBeautifulSoup.object_was_parsed\u001b[39m\u001b[34m(self, o, parent, most_recent_element)\u001b[39m\n\u001b[32m    864\u001b[39m         o = containerClass(current_data)\n\u001b[32m    865\u001b[39m         \u001b[38;5;28mself\u001b[39m.object_was_parsed(o)\n\u001b[32m--> \u001b[39m\u001b[32m867\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mobject_was_parsed\u001b[39m(\n\u001b[32m    868\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    869\u001b[39m     o: PageElement,\n\u001b[32m    870\u001b[39m     parent: Optional[Tag] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    871\u001b[39m     most_recent_element: Optional[PageElement] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    872\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    873\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Method called by the TreeBuilder to integrate an object into the\u001b[39;00m\n\u001b[32m    874\u001b[39m \u001b[33;03m    parse tree.\u001b[39;00m\n\u001b[32m    875\u001b[39m \n\u001b[32m    876\u001b[39m \u001b[33;03m    :meta private:\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m parent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ✅ 設定資料夾路徑\n",
    "folder_path = \"/Users/timothy/Desktop/allofplos\"\n",
    "\n",
    "records = []\n",
    "xml_files = [f for f in os.listdir(folder_path) if f.endswith(\".xml\")]\n",
    "\n",
    "start_idx = 17600\n",
    "batch_size = 50000\n",
    "csv_base = \"plos_all_cleaned\"\n",
    "\n",
    "for idx, file in enumerate(tqdm(xml_files), 1):\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    records.extend(parse_authors_from_xml(file_path))\n",
    "\n",
    "    if idx % batch_size == 0:\n",
    "        df = pd.DataFrame(records)\n",
    "        df.to_csv(f\"{csv_base}_up_to_{idx}.csv\", index=False)\n",
    "        print(f\"✔️ 儲存進度：已處理 {idx} 筆\")\n",
    "\n",
    "# 最終儲存一次完整資料\n",
    "df = pd.DataFrame(records)\n",
    "df.to_csv(f\"{csv_base}_final.csv\", index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87cbb05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='plos_research_only.csv' target='_blank'>plos_research_only.csv</a><br>"
      ],
      "text/plain": [
       "/Users/timothy/Desktop/plos_research_only.csv"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 顯示下載連結\n",
    "FileLink(\"plos_research_only.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da0c6eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8p/k5cclwt549dg7s3z944xq9h80000gn/T/ipykernel_62045/1083731973.py:3: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv('plos_all_cleaned_up_to_17600.csv')\n",
      "/var/folders/8p/k5cclwt549dg7s3z944xq9h80000gn/T/ipykernel_62045/1083731973.py:4: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv('plos_all_cleaned_up_to_50000.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv('plos_all_cleaned_up_to_17600.csv')\n",
    "df2 = pd.read_csv('plos_all_cleaned_up_to_50000.csv')\n",
    "\n",
    "merged_df = pd.concat([df1, df2], ignore_index=True)\n",
    "merged_df.to_csv('plos_all_cleaned_up_to_67600.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8ad5a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
