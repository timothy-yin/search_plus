import streamlit as st
import pandas as pd
import re

st.set_page_config(page_title="PLOS å°ˆé¡Œè³‡æ–™è§€å¯Ÿå¹³å°", layout="wide")
st.title("ðŸ“˜ PLOS Article Explorerï¼ˆ67600ï¼‰")

@st.cache_data
def load_data():
    df = pd.read_csv("plos_all_cleaned_up_to_67600.csv")
    author_counts = df.groupby(["DOI", "Title"]).size().reset_index(name="AuthorCount")
    df = df.merge(author_counts, on=["DOI", "Title"])
    df["Year"] = df["DOI"].str.extract(r'10\.1371/journal\.pone\.(\d{2})', expand=False)
    df["Year"] = df["Year"].apply(lambda x: int("20" + x) if pd.notnull(x) else None)

    # å»ºç«‹ capped æ¬„ä½ï¼ˆå¦‚ >50 â†’ 51ï¼‰
    df["AuthorCapped"] = df["AuthorCount"].apply(lambda x: x if x <= 50 else 51)
    return df

df = load_data()

# Sidebar filters
st.sidebar.header("ðŸ” æª¢ç´¢è¨­å®š")
search_column = st.sidebar.selectbox(
    "è«‹é¸æ“‡è¦æª¢ç´¢çš„æ¬„ä½",
    ["DOI", "Title", "Author", "Affiliation", "Role", "Subjects", "Keywords", "Abstract"]
)
search_mode = st.sidebar.radio("æª¢ç´¢æ¨¡å¼", ["é—œéµå­—ï¼ˆæ¨¡ç³Šæ¯”å°ï¼‰", "æ­£å‰‡è¡¨é”å¼ï¼ˆRegexï¼‰"])
search_input = st.sidebar.text_input("è¼¸å…¥æª¢ç´¢å…§å®¹")

# ä½œè€…æ•¸é‡æ»‘æ¡¿ï¼ˆ51 è¡¨ç¤º 50+ï¼‰
author_slider = st.sidebar.slider("é¸æ“‡ä½œè€…æ•¸ï¼ˆæœ€å¤§ 50+ï¼‰", min_value=1, max_value=51, value=(1, 10))
mask = df["AuthorCapped"].between(author_slider[0], author_slider[1])

# å¹´ä»½è¤‡é¸
year_options = sorted(df["Year"].dropna().astype(int).unique().tolist())
selected_years = st.sidebar.multiselect("é¸æ“‡ç™¼è¡¨å¹´ä»½ï¼ˆå¯è¤‡é¸ï¼‰", year_options, default=year_options)
mask &= df["Year"].isin(selected_years)

# è§’è‰²
role_filter = st.sidebar.multiselect("ä½œè€…è§’è‰²ï¼ˆå¯è¤‡é¸ï¼‰", ["ç¬¬ä¸€ä½œè€…", "é€šè¨Šä½œè€…"])

# é¡¯ç¤ºç­†æ•¸
max_results = st.sidebar.slider("é¡¯ç¤ºæ–‡ç« æ•¸é‡", 5, 100, 20)

# æœå°‹æŒ‰éˆ•
do_search = st.sidebar.button("ðŸš€ é–‹å§‹æœå°‹")

if do_search:
    if role_filter:
        role_mask = df["Role"].fillna("").apply(lambda r: any(role in r for role in role_filter))
        mask &= role_mask

    if search_input:
        if search_mode == "é—œéµå­—ï¼ˆæ¨¡ç³Šæ¯”å°ï¼‰":
            mask &= df[search_column].fillna("").str.contains(search_input, case=False)
        else:
            try:
                mask &= df[search_column].fillna("").str.contains(search_input, regex=True)
            except re.error:
                st.error("âŒ ç„¡æ•ˆçš„æ­£å‰‡è¡¨é”å¼")
                mask &= pd.Series([False] * len(df))

    filtered = df[mask]
    unique_articles = filtered.drop_duplicates(subset=["DOI", "Title"]).head(max_results)

    if not unique_articles.empty:
        st.success(f"ðŸ”Ž æ‰¾åˆ° {len(unique_articles)} ç¯‡ç¬¦åˆçš„æ–‡ç« ")
        for _, row in unique_articles.iterrows():
            with st.expander(f"{row['Title']} ({row['DOI']})"):
                st.markdown(f"**DOI**: {row['DOI']}")
                st.markdown(f"**Subjects**: {row['Subjects']}")
                st.markdown(f"**Keywords**: {row['Keywords']}")
                st.markdown(f"**Abstract**: {row['Abstract']}")

                authors = filtered[(filtered["DOI"] == row["DOI"]) & (filtered["Title"] == row["Title"])][["Author", "Affiliation", "Role"]]
                st.markdown("**ä½œè€…åˆ—è¡¨ï¼š**")
                st.dataframe(authors, use_container_width=True)

        st.download_button("ðŸ“¥ åŒ¯å‡ºçµæžœ CSV", data=unique_articles.to_csv(index=False), file_name="plos_search_articles.csv")
    else:
        st.warning("â— æŸ¥ç„¡ç¬¦åˆæ¢ä»¶çš„è³‡æ–™ï¼Œè«‹èª¿æ•´æœå°‹æ¢ä»¶å¾Œé‡è©¦ã€‚")
else:
    st.info("è«‹åœ¨å·¦å´è¨­å®šæª¢ç´¢æ¢ä»¶ï¼Œé»žé¸ ðŸš€ é–‹å§‹æœå°‹")
